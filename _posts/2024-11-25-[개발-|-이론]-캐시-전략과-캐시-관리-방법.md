---
layout: post
date: 2024-11-25
title: "[개발 | 이론] 캐시 전략과 캐시 관리 방법"
tags: [cache, ]
categories: [백엔드, 이론, ]
mermaid: true
---



### **1. 읽기 중심의 애플리케이션 캐싱**



#### 1. 1. 캐시 별도 관리(Cache-Aside)


![0](/assets/img/2024-11-25-개발--이론-캐시-전략과-캐시-관리-방법.md/0.png)


**작동 원리**

1. 요청이 들어오면 캐시저장소를 먼저 확인
2. 캐시에 데이터가 없다면 DB에서 조회
=> 일반적으로 이때 조회한 결과를 캐싱한다.

**장점/단점**


장점: 구현이 단순하며, 캐시저장소 장애 상황에 대응이 가능하다.
단점: 최초 요청 또는 한 번의 캐시 미스는 눈에 띄는 지연이 발생한다.



#### 1. 2. 캐시 통해서 읽기(Read-Through)


![1](/assets/img/2024-11-25-개발--이론-캐시-전략과-캐시-관리-방법.md/1.png)


**작동 원리**

1. 요청이 들어오면 캐시저장소에 조회를 한다.
2. 캐시된 데이터가 없다면 캐시저장소가 직접 DB에 쿼리를 한다.

	→ 보통 캐시 key가 질의할 SQL이 된다고 한다.

3. 캐시 저장소는 DB에서 응답받은 데이터를 캐싱하고 App에 응답한다.

**장점/단점**


장점: App 입장에서는 캐시저장소 하고만 상호작용하기 때문에 코드가 단순해진다.

- 일반적인 구현에서는 캐시저장소가 동시에 동일한 쿼리를 한 번만 DB요청 하도록 설계하기 때문에 DB에게 적은 부하를 줄 수 있다.
- 디스코드 글 참고: [how-discord-stores-trillions-of-messages](https://discord.com/blog/how-discord-stores-trillions-of-messages#heading-4)

단점: 캐시저장소과 APP간에 결합이 매우 높기 때문에 캐시저장소의 장애 대응 정책이 중요하다.



#### 1. 3. 캐시 미리 갱신(Refresh-Ahead)


> 💡 Refresh-Ahead는 캐시 키의 구현보다는 만료 시간(TTL) 관리에 초점이 맞춰져 있습니다.


![2](/assets/img/2024-11-25-개발--이론-캐시-전략과-캐시-관리-방법.md/2.png)


**작동 원리**

1. 백그라운드 작업이 주기적으로 자주 접근되는 캐시 항목들을 만료 전에 미리 갱신한다.
2. TTL과 refresh-ahead factor를 설정하여 갱신 시점을 결정한다.

	→ 예를 들어, TTL이 120초이고 refresh-ahead factor가 0.5라면, 60초가 지난 시점에서 비동기적으로 데이터를 미리 갱신한다.


**구현 방식**

- 캐시 제공자(Cache Provider)에 따라 구현 방식이 달라진다.
- CDC 기능을 사용하여 DB 변경사항을 감지하고 캐시를 갱신하는 방식도 가능하다.


### **2. 쓰기 중심의 애플리케이션 캐싱**



#### **2.1. 캐시 통해서 쓰기(Write-Through)**


![3](/assets/img/2024-11-25-개발--이론-캐시-전략과-캐시-관리-방법.md/3.png)


**작동 원리**

1. 쓰기 요청이 들어오면 캐시저장소에 데이터를 작성한다.
2. 캐시 저장소는 **동기적**으로 DB에 데이터를 작성한다.

**장점/단점**

- **캐시 통해서 읽기(Read-Through)와 같이 쓰기 적합하다.**


#### **2.2. 쓰고 나서 캐시(Write-behind)**


> 💡 **캐시 통해서 쓰기(Write-Through)와 유사하며, DB 쓰기가 비동기적으로 동작한다는 차이가 있다.**


![4](/assets/img/2024-11-25-개발--이론-캐시-전략과-캐시-관리-방법.md/4.png)


**작동 원리**

1. 쓰기 요청이 들어오면 캐시저장소에 저장하고 응답한다.
2. 캐시 저장소는 **비동기적**으로 DB에 데이터를 작성한다.

	→ 일반적으로 데이터 저장은 batch 방식으로 이루어진다.


		ex) 100건이 쌓이면 동기화 한다., 5초간 쌓인 데이터를 동기화 한다.


**장점/단점** 

- 쓰기 성능을 위한 전략으로 대량의 쓰기 작업이 있는 경우 적합하다.
- **캐시 통해서 읽기(Read-Through)와 같이 쓰기 적합하다.**
- batch 방식 쓰기가 가능하기 때문에 **쓰기 작업에 대한 비용을 줄이는데 효과적**이다.
- **가장 큰 단점**은 DB에 쓰기 동작이 수행되기 전에 캐시저장소가 죽게되면 **데이터 유실의 위험**이 존재한다.(Redis에서는 이러한 단점을 보완하는 기능을 제공하기도 한다.)


#### **2.3. 캐시 나중에 쓰기(Write-Around)**


![5](/assets/img/2024-11-25-개발--이론-캐시-전략과-캐시-관리-방법.md/5.png)


> 📌 캐싱을 건너 뛰고 DB에 쓰기를 수행한다. 


**처리 과정**

1. 쓰기 요청이 들어오면 DB에 데이터를 작성한다.
	- 주로 조회 시점이 캐시 미스가 발생하면, 그 때 캐싱을 수행한다.
	- 비동기적으로 캐싱도 가능하다.

**장점/단점**

- 구현이 단순하고, 캐시 저장소에 대한 고려가 필요 없기 때문에 캐시저장소 장애 상황에 대응이 가능하다.
- 읽기 시점에 캐싱하기 때문에 자주 읽히지 않을 데이터를 쓸 때 유용하며, 캐시 공간을 효율적으로 사용이 가능하다.

**조합**

- 주로 캐시 별도 관리(Cache-Aside) 결합해서 사용한다.
- 또한 캐시 통해서 읽기(Read-Through)와 결합하여 데이터가 한 번 쓰여지고 자주 또는 전혀 읽히지 않는 상황에서 좋은 성능을 보인다.


### 3. 캐시 관리 방법



#### 3.1. 캐시 무효화 전략

- 시간 기반(TTL) 무효화
- 이벤트 기반 무효화
- 버전 기반 무효화
- 최근에 사용하지 않은 데이터(LRU) 무효화
- 수동 무효화


### 4. 토스 글로 보는 캐시 문제 관리 방법


[https://toss.tech/article/cache-traffic-tip](https://toss.tech/article/cache-traffic-tip)



#### **4.1. 캐시 쇄도(Cache Stampede)**


> 📌 캐시 미스가 동시에 많이 발생하는 상황


![6](/assets/img/2024-11-25-개발--이론-캐시-전략과-캐시-관리-방법.md/6.png)


매일 자정에 캐시를 갱신하는 경우를 생각해보자 갱신 시간에 맞춰 캐시가 일제히 만료되도록 설계하는 방식이 가장 일반적으로 사용된다. 


하지만 갱신 시점에 트래픽이 집중된다면 장애 발생의 위험이 높아진다.


**해결안: 지터(Jitter)**


캐시 만료 시간을 무작위로 조금 지연시키면, 캐시 쇄도 상황에서 데이터베이스의 부하를 균등하게 분산할 수 있다.


> ‘지터(Jitter)’는 전자공학에서 나온 개념으로 전자 신호를 읽는 과정에서 발생하는 짧은 지연 시간을 의미한다.


지터를 간단하게 구현하는 방법은 캐시 만료 시간에 0~10초 사이의 무작위 지연 시간을 추가하는 것이다. 이렇게 하면 일괄적으로 캐시가 만료되는 것이 아닌 0 ~ 10초의 랜덤한 시간이 추가되어 데이터베이스의 부하를 분산할 수 있다.



#### **4.2. 캐시 관통(Cache Penetration)**


> 📌 데이터베이스를 읽었는데 캐싱이 되지 않는 상황을 “캐시 관통”이라고 한다.


![7](/assets/img/2024-11-25-개발--이론-캐시-전략과-캐시-관리-방법.md/7.png)


보통 캐시에서 `null` 값이 반환되면, 데이터베이스를 조회해서 캐싱을 수행한다. 여기서 진짜 DB에 데이터가 없어서 `null`이 반환되는 경우를 생각해보자. 


이 경우 데이터베이스를 읽었는데도 캐시가 수행되지 않았기 때문에 항상 DB로 트래픽이 전달되는 문제가 발생한다.


**해결안: 널 오브젝트 패턴(Null Object Pattern)**

1. 블룸필터: “값이 없음”을 캐싱하는 것이다.

	> 이러한 방법을 [블룸필터](https://en.wikipedia.org/wiki/Bloom_filter)라고 한다. **블룸 필터를 사용하면 확률적으로 캐시 관통을 방지해요. 하지만 블룸 필터의 정합성이 깨진다면, 블룸 필터를 복구하기 위해 모든 캐시를 읽어야 해서 운영이 어려워요.**

1. **널 오브젝트 패턴(Null Object Pattern)**

	“값이 없음”을 나타내는 값을 지정해서 캐싱한다. DB에 명시적으로 “NULL” 또는 “NONE”을 넣는 경우가 있는데 이것과 비슷하다.



#### **4.3. 캐시 시스템 장애**


![8](/assets/img/2024-11-25-개발--이론-캐시-전략과-캐시-관리-방법.md/8.png)


트래픽이 적은 경우에 캐시저장소의 장애는 큰 문제가 되지 않을 수 있지만, 트래픽이 피크를 치는 상황에서는 매우 위험할 수 있다. 모든 트래픽이 DB에 직접적으로 가게되어 DB의 장애 상황으로 이어질 수 있기 때문이다.


**해결안: 대체 작동(Failover)**


캐시 시스템의 결함의 경우 그냥 캐시 복구까지 서비스를 잠시 중단하는게 좋은 방법일 수 있다.


중단이 어렵다면 핵심 기능을 미리 정의하고 편의를 위한 부가 기능을 잠시 중단하고 핵심 기능만 사용하게 해 DB에 트래픽을 낮추는 방향을 모색해야한다.


주의: 캐시 기능을 만들다 보면, 캐시저장소가 장애시 데이터베이스로 Fallback하는 코드로 단순하게 작성하기 쉽다. 



#### **4.4. 핫(Hotkey) 만료**


> 📌 많은 요청이 집중되는 키를 '핫키'라고 한다.  
> - “유명 인사 키”라고 하기도 한다.

	- “유명 인사 키”라고 하기도 한다.

![9](/assets/img/2024-11-25-개발--이론-캐시-전략과-캐시-관리-방법.md/9.png)


핫키가 만료되면, 캐시가 갱신되기 전에 순간적으로 많은 요청이 DB로 요청될 수 있다. 이러한 경우를 막기 위해 ‘핫키’는 캐시의 만료 기한을 없에거나 백그라운드에서 주기적으로 캐싱되게 해야한다.


하지만 이러한 방법은 핫키가 더 이상 핫키가 되지 않았을때와 핫키만 별도로 관리하는 로직이 필요하기 때문에 관리가 쉽지않다. 


**해결안: 분산 락(Distributed Lock)**


분산락을 사용해서 동시에 들어오는 캐싱 요청을 하나만 처리 되도록 할 수 있다.


> 캐시를 애플리케이션 서버 간의 **공유 자원**으로 볼 수 있습니다. 캐시 미스가 발생했을 때 락을 설정하고 캐싱한 후에 락을 해제함으로써, 단 **한 번의 쓰기 작업만 허용**할 수 있고요.


비슷한 방법으로 쓰기를 최적화한 글

- 디스코드 참고: [how-discord-stores-trillions-of-messages](https://discord.com/blog/how-discord-stores-trillions-of-messages#heading-4)

---



### 레퍼런스

- [https://soobing.github.io/cs/6-caching-strategies/](https://soobing.github.io/cs/6-caching-strategies/)
- [https://toss.tech/article/cache-traffic-tip](https://toss.tech/article/cache-traffic-tip)
